[AAAI-22 UC @ the AAAI site ](https://aaai.org/Conferences/AAAI-22/undergraduate-consortium/)  
Return to [the main AAAI Undergraduate Consortium page](https://aaai-uc.github.io/)

[AAAI 2022 main site](http://aaai.org/Conferences/AAAI-22/)  
Thirty-Sixth AAAI Conference on Artificial Intelligence  
February 22 - March 1, 2022


# AAAI-22 Undergraduate Consortium 

See our AAAI-22 scholars talk about their research! The youtube playlist of AAAI-22 UC pitch videos is [available here](https://www.youtube.com/watch?v=dXsupAQAKgs&list=PLIsth1r16Z2MHJ9jItF2MLGzQgAjH8QN8), and links to individual videos accompany each scholar's profile, below. 

# Meet our scholars!

## Vishakha Agrawal
<img width="200" alt="Photo" src="./2022/photos/Vishakha.jpg"> <br>
Department of Information Science and Engineering  <br>
Dayananda Sagar College of Engineering  <br>
[https://vishakha-a.github.io/](https://vishakha-a.github.io) <br>
<!--[3-min pitch video](https://www.youtube.com/watch?v=0E2jPSKyNQk&list=PLIsth1r16Z2MHJ9jItF2MLGzQgAjH8QN8&index=7)  <br>-->

I am a senior undergraduate student majoring in information science. Upon the completion of my undergraduate degree, I plan to pursue a Ph.D. in computer science. My research interests and experiences lie within the broad area of trustworthy machine learning. More specifically, my research spans explainable, fair, and robust ML. I am also very interested in AI ethics and algorithmic justice. In my free time, I enjoy hiking, napping, and attending conferences.

### Abstract 
The concerns about AI-driven decision-making stems from the potential of technology, such as computer vision, for policing, social control, and surveillance by both state and corporate interests. Already, social credit systems (SCS) have been deployed by the Chinese government in different regions of China. The discussions around the SCS are ambiguous: some people call them very controversial and a breach of human rights, while others say that the SCS and related surveillance systems are very similar in structure to the normal credit systems in the United States. In reality, though, there is no monolith and there are various different forms of mass surveillance and SCS deployed in different regions of China. I review and analyze these different models of the SCS. I also compare how the different systems are upholding or breaching China’s own AI ethics guidelines. In future work, I hope to present the Chinese SCS as a form of future control systems, a post-Foucauldian world, wherein jails are no longer required. 

## Hannah M. Claus
<img width="200" alt="Photo" src="./2022/photos/Hannah.png"> <br>
School of Computer Science and Technology  <br>
University of Bedfordshire  <br>
[https://www.linkedin.com/in/hannah-claus-042382199/](https://www.linkedin.com/in/hannah-claus-042382199/)  <br>
[3-min pitch video](https://www.youtube.com/watch?v=eyRyz5ltcco&list=PLIsth1r16Z2MHJ9jItF2MLGzQgAjH8QN8&index=4)  <br>

Hannah M. Claus is a senior undergraduate pursuing a Bachelor of Science in Artificial Intelligence and Robotics at the University of Bedfordshire. She started programming at the age of 13 when she was the only girl in the Computer Science class at school. After receiving a scholarship by the Hasso-Plattner-Institute twice, where she could visit university lectures and deepen her knowledge on Software Engineering, she got the opportunity to study at the Technical University Berlin while still going to school. After those four years of simultaneously visiting university and school, she graduated at the age of 18 and decided to deepen her studies of AI and Robotics abroad in the UK. During her studies she is also working voluntarily for various organisations that support women and people of colour in STEM areas. Hannah is a published researcher and is working towards the goal to give more girls and women all around the world the opportunity to excel in STEM by making knowledge more accessible. As part of a research team of the German Aerospace Center (DLR), she is currently working on creating machine learning classifiers that detect and classify collisions for the humanoid robot Rollin' Justin to extend the applications of robots in space exploration.

### Abstract 
This paper explores the importance of using optimisation techniques when tuning a machine learning model. The hyperparameters that need to be determined for the Artificial Neural Network (ANN) to work most efficiently, are supposed to find a value that achieves the highest recognition accuracy in a face recognition application. First, the model was trained without an optimisation technique. The highest recognition accuracy that could be achieved was 96.6% with a specific set of parameters used in the ANN. However, the error rate was at 30%, which was not optimal. After utilising Grid Search as the first tuning method for hyperparameters, the recognition accuracy rose to 96.9% and the error rate could be minimised to be less than 1%. Applying Random Search, a recognition accuracy of 98.1% could be achieved with the same error rate. Hence, the accuracy of the facial recognition application could be increased by at least 2.1% by applying automated optimisation algorithms. Furthermore, this paper will also deal with common issues in face recognition (i.e. racial bias and gender bias) and focus on potential solutions. 

## Amelia Lee Dogan
<img width="200" alt="Photo" src="./2022/photos/Amelia.jpeg"> <br>
Department of Urban Studies and Planning and Department of Electrical Engineering and Computer Science <br>
Massachusetts Institute of Technology <br>
[3-min pitch video](https://www.youtube.com/watch?v=XkU9ZXvMJtU&list=PLIsth1r16Z2MHJ9jItF2MLGzQgAjH8QN8&index=10)  <br>

Amelia Lee Dogan (she/they) is an undergraduate student studying Urban Planning with Computer Science and American Studies at the Massachusetts Institute of Technology. Currently, she works at the Data + Feminism Lab researching data activism. Previously, they have worked at Google, the US Department of Transportation Volpe Center, West Philadelphia Landscape Project, and Movement Alliance Project/Vietlead. Her research interests primarily examine how communitie of color use data science for co-liberation. She’s from occupied Lenape land (Philadelphia/NYC) and Coast Salish territories (Vancouver). 

### Abstract 
After criminal recidivism or hiring machine learning models have inflicted harm, participatory machine learning methods are often used as a corrective positioning. However, little guidance exists on how to develop participatory machine learning models in a ground-up format. Here we demonstrate how to co-design and partner with community groups, in the specific case of feminicide data activism. We co-designed and piloted a machine learning model for the detection of feminicide media articles. This provides an intersectional feminist perspective on practicing participatory methods in a co-creation mindset for the real-world scenario of feminicide monitoring.

## Abigail Swenor
<img width="200" alt="Photo" src="./2022/photos/Abigail.jpg"> <br>
Department of Computer Science  <br>
University of Colorado - Colorado Springs  <br>
[3-min pitch video](https://www.youtube.com/watch?v=O1Ud9TTHFtw&list=PLIsth1r16Z2MHJ9jItF2MLGzQgAjH8QN8&index=11)  <br>

Abigail Swenor is an undergraduate student at the University of Colorado - Colorado Springs (UCCS) majoring in computer science with minors in mathematics, computer engineering, and philosophy. She is an undergraduate researcher for the Language Information and Computation Lab at UCCS. Her research interests are in Natural Language Processing (NLP) and Machine Learning, and she is currently working with defense methods for adversarial attacks on NLP models. Abigail plans to pursue a PhD in computer science after completing her undergraduate studies at UCCS. 

### Abstract 
Deep learning models have excelled in solving many difficult problems in Natural Language Processing (NLP), but it has been demonstrated that such models are susceptible to extensive vulnerabilities. We offer a solution to this vulnerability by using, during testing, random perturbations such as spelling correction if necessary, substitution by random synonym, or simply dropping the word. These perturbations are applied to random words in random sentences to defend NLP models against adversarial attacks. Our Random Perturbations Defense and Increased Randomness Defense methods are successful in returning attacked models to their original accuracy within statistical significance. 

## Mira Welner
<img width="200" alt="Photo" src="./2022/photos/Mira.jpg"> <br>
Electrical and Computer Engineering  <br>
University of California, Davis  <br>
[burningsilicon.dev](burningsilicon.dev)  <br>
[3-min pitch video](https://www.youtube.com/watch?v=3JrT1o2ICKs&list=PLIsth1r16Z2MHJ9jItF2MLGzQgAjH8QN8&index=3)  <br>

I am a senior at UC Davis and hope to get a PhD in computer vision and robotics. For three years I have worked at prosthetics and robotics lab designing user studies to study the muscular motions of young children. For two years I have worked in a machine learning lab studying what factors will cause a study to translate from preclinical to clinical succesfully. Last summer I worked with Professor Aswin Sankarankarayanan studyign hyperspectral images at Carnegie Mellon University. I hope to apply machine learning and computer vision to space travel.

### Abstract 
We introduce a novel technique to identify the three primary materials in a scene as displayed by a hyperspectral image using unsupervised learning. We designed a modified autoencoder which compresses the hyperspectral image using convolutional neural networks, but unlike most autoencoders, decompresses the images using linear algebra. This ensures that unlike standard the latent features of the compressed images contain data understandable by humans. The linear algebra used for decompression relies on the properties of hyperspectral images. The resulting three spectra are intended to resemble the spectra of the actual materials in the scene but further research is necessary to determine if this is true. 

